# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved
import json
from pathlib import Path
import random
import math
import os

import matplotlib.pyplot as plt
import numpy as np
import torch
import torchvision
from torchvision.datasets import CocoDetection
from PIL import Image
from pycocotools.coco import COCO

from panopticapi.utils import rgb2id
from util.box_ops import masks_to_boxes, box_xywh_to_xyxy

from .coco import make_coco_transforms # TO DO: will want to use own PET specifc transforms


# Need own loader as reading from same .npy for image and masks
class PETCT_CocoDetection(CocoDetection):
    def __init__(self, img_folder, ann_file, transforms, return_masks, training=False):
        super(PETCT_CocoDetection, self).__init__(img_folder, ann_file)
        self._transforms = transforms
        self.return_masks = return_masks
        self.img_folder = img_folder
        self.training = training
        self.ann_file = ann_file
        self.prepare = ConvertSUVtoGrey(return_masks)
        
#         self.coco = COCO(annFile)
#         self.ids = list(sorted(self.coco.imgs.keys()))
    
#     def __init__(
#         self,
#         root: str,
#         annFile: str,
#         transform: Optional[Callable] = None,
#         target_transform: Optional[Callable] = None,
#         transforms: Optional[Callable] = None,
#     ) -> None:
#         super().__init__(root, transforms, transform, target_transform)
#         from pycocotools.coco import COCO

#         self.coco = COCO(annFile)
#         self.ids = list(sorted(self.coco.imgs.keys()))

#     def _load_image(self, id: int) -> Image.Image:
#         path = self.coco.loadImgs(id)[0]["file_name"]
#         return Image.open(os.path.join(self.root, path)).convert("RGB")
    
    
    # reading from a .npy file with presaved img (in suv values) and masks
    def _load_image_masks(self, id: int):
        npy_name = self.coco.loadImgs(id)[0]["file_name"] # loads a .npy file by image_id
        img_ann_path = self.img_folder/Path(npy_name)
        with open(img_ann_path, 'rb') as f:
            suv_img = np.load(f) # this is a single channel suv values image, dtype numpy float64
            masks = np.load(f)
        return (suv_img, masks)
    
    def _load_target(self, id: int):        #already inherited from CocoDetection
        return self.coco.loadAnns(self.coco.getAnnIds(id))
    
    #torchvision CocoDetection makes a list of all image_ids, pycocotool coco maps image_ids to images and annotations
    def __getitem__(self, idx):
        image_id = self.ids[idx] #self.ids, an ordered list of image_ids generated by torchvision CocoDetection
        img, masks = self._load_image_masks(image_id)
        target = self._load_target(image_id)[0] #inherited this from torchvision CocoDetection
        target = {'image_id': image_id, 'annotations': target}
        
        if self.training:
            # Random augmentation for SUV normalization to gray images
            suv_values = [5,6,7,8,9,10,15,20]
            suv_max = random.choice(suv_values)
        else:
            suv_max = 6
        img, target = self.prepare(img, target, masks, suv_max)
        
        if self._transforms is not None:
            #print('normalizing image ###')
            img, target = self._transforms(img, target)
            #print('normalized ####')

        return img, target

    def __len__(self):
        return len(self.ids)

    def get_height_and_width(self, idx):
        img_info = self.coco['images'][idx]
        height = img_info['height']
        width = img_info['width']
        return height, width
    
    def get_img_demo(self, idx):
        img_info = self.coco['images'][idx]
        age = img_info['age']
        sex = img_info['sex']
        diagnosis = img_info['diagnosis']
        return age, sex, diagnosis
    
    def get_img_suv(self, idx):
        stats = self.coco['images'][idx]['nii_stats']
        liver_suv = stats['liver']
        brain_suv = stats['brain']
        max_suv = stats['suv_max'] 
        return liver_suv, brain_suv, max_suv
    
    def get_dcm_spacing(self, idx):
        stats = self.coco['images'][idx]['nii_stats']
        w = stats['pixdim'][1]
        y = stats['pixdim'][3]
        spacing = (1, y/w)
        return spacing


class ConvertSUVtoGrey(object):
    def __init__(self, return_masks=False):
        self.return_masks = return_masks

    def __call__(self, suv_img, target, masks, suv_max):
        # Assuming eval mode
        norm = plt.Normalize(vmin = 0, vmax = suv_max) # normally radiologists view images at this suv norm
        # Color map to gray images, output has 3 channels
        cmap = plt.cm.Greys
        img = cmap(norm(suv_img))[:,:,:3].copy() # drop the alpha channel that we don't need. has shape (H x W x 3C) 
        #img = torch.as_tensor(img, dtype=torch.float64) # the transforms latera will turn the numpy array to a tensor (C x H x W)
        img = Image.fromarray(np.uint8(img*255), 'RGB') # expected input by transforms
        #print(img.size, '####')
        w, h = img.size

        image_id = target["image_id"]
        image_id = torch.tensor([image_id])

        if 'segments_info' in target["annotations"]:
            anno = target["annotations"]['segments_info']
        else:
            anno = target["annotations"]

        anno = [obj for obj in anno if 'iscrowd' not in obj or obj['iscrowd'] == 0]

        #transforms expects xyxy format boxes -- but not sure what pycocotool expects ***, maybe xywh or xyxy
        boxes = [obj["bbox"] if obj['area'] != 0 else [0,0,w,h] for obj in anno]
        # guard against no boxes via resizing --> code below actually turns xywh to xyxy
        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)
        boxes[:, 2:] += boxes[:, :2]
        # makes sure boxes don't go outside image
        boxes[:, 0::2].clamp_(min=0, max=w)
        boxes[:, 1::2].clamp_(min=0, max=h)

        target = {}
        target["boxes"] = boxes
        target["labels"] = torch.as_tensor([obj["category_id"] for obj in anno], dtype=torch.int64)
        if self.return_masks:
            target["masks"] = torch.as_tensor(masks, dtype=torch.uint8)
        target["image_id"] = image_id
        target["area"] = torch.as_tensor([obj["area"] for obj in anno])
        target["iscrowd"] = torch.as_tensor([obj["iscrowd"] if "iscrowd" in obj else 0 for obj in anno])
        target["orig_size"] = torch.as_tensor([int(h), int(w)])
        target["size"] = torch.as_tensor([int(h), int(w)])

        #print(img)
        #print(target)
        return img, target
    

def build(image_set, args):
    root = Path(args.coco_petct_path)
    assert root.exists(), f'provided COCO path {root} does not exist'
    
    mode = 'detr'
    PATHS = {
        "train": (root/ "images/train", root / "annotations" / f'{mode}_train_0.9.json'), 
        "val": (root/ "images/train", root / "annotations" / f'{mode}_val_0.1.json'), 
        "test": (root/ "images/test", root / "annotations" / f'{mode}_test.json'), # this will be set aside for final testing
    }
    img_folder, ann_file = PATHS[image_set]
    
    if image_set == 'train':
        training = True
    else:
        training = False
    
    dataset = PETCT_CocoDetection(img_folder, ann_file, transforms=make_coco_transforms(image_set)
                                 , return_masks=args.masks, training = training)
    
    return dataset    
    
    

