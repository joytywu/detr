# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved
import json
from pathlib import Path
import random
import math
import os

import matplotlib.pyplot as plt
import numpy as np
import torch
import torchvision
from torchvision.datasets import CocoDetection
from PIL import Image
from pycocotools.coco import COCO

from panopticapi.utils import rgb2id
from util.box_ops import masks_to_boxes, box_xywh_to_xyxy

from .coco import make_coco_transforms # TO DO: will want to use own PET specifc transforms


# Need own loader as reading from same .npy for image and masks
class PETCT_CocoDetection(CocoDetection):
    def __init__(self, img_folder, ann_file, transforms, return_masks, training=False):
        super(PETCT_CocoDetection, self).__init__(img_folder, ann_file)
        self._transforms = transforms
        self.return_masks = return_masks
        self.img_folder = img_folder
        self.training = training
        self.ann_file = ann_file
        self.prepare = Convert_SUVtoGreyPIL_RLEtoMask(return_masks)

#     # reading from a .npy file with presaved img (in suv values) and masks
#     def _load_image_masks(self, id: int):
#         npy_name = self.coco.loadImgs(id)[0]["file_name"] # loads a .npy file by image_id
#         img_ann_path = self.img_folder/Path(npy_name)
#         with open(img_ann_path, 'rb') as f:
#             suv_img = np.load(f) # this is a single channel suv values image, dtype numpy float64
#             masks = np.load(f)
#         return (suv_img, masks)

    def _load_image_npy(self, id: int):
        npy_name = self.coco.loadImgs(id)[0]["file_name"] # loads a .npy file by image_id
        img_ann_path = self.img_folder/Path(npy_name)
        with open(img_ann_path, 'rb') as f:
            suv_img = np.load(f) # this is a single channel suv values image, dtype numpy float64
        return suv_img

    def _load_target(self, id: int):        #same as from CocoDetection
        return self.coco.loadAnns(self.coco.getAnnIds(id))
    
    #torchvision CocoDetection makes a list of all image_ids, pycocotool coco maps image_ids to images and annotations
    def __getitem__(self, idx):
        image_id = self.ids[idx] #self.ids, an ordered list of image_ids generated by torchvision CocoDetection
        img = self._load_image_npy(image_id) #COCO load image doesn't work with .npy
        target = self._load_target(image_id)[0] #inherited this from torchvision CocoDetection
        target = {'image_id': image_id, 'annotations': target}
        
        if self.training:
            # Random augmentation for SUV normalization to gray images
            suv_values = [5,6,7,8,9,10,15,20]
            suv_max = random.choice(suv_values)
        else:
            suv_max = 6
        img, target = self.prepare(img, target, masks, suv_max)
        
        if self._transforms is not None:
            #print('normalizing image ###')
            img, target = self._transforms(img, target)
            #print('normalized ####')

        return img, target

    def __len__(self):
        return len(self.ids)

    def get_height_and_width(self, idx):
        img_info = self.coco['images'][idx]
        height = img_info['height']
        width = img_info['width']
        return height, width
    
    def get_img_demo(self, idx):
        img_info = self.coco['images'][idx]
        age = img_info['age']
        sex = img_info['sex']
        diagnosis = img_info['diagnosis']
        return age, sex, diagnosis
    
    def get_img_suv(self, idx):
        stats = self.coco['images'][idx]['nii_stats']
        liver_suv = stats['liver']
        brain_suv = stats['brain']
        max_suv = stats['suv_max'] 
        return liver_suv, brain_suv, max_suv
    
    def get_dcm_spacing(self, idx):
        stats = self.coco['images'][idx]['nii_stats']
        w = stats['pixdim'][1]
        y = stats['pixdim'][3]
        spacing = (1, y/w)
        return spacing


class Convert_SUVtoGreyPIL_RLEtoMask(object):
    def __init__(self, return_masks=False):
        self.return_masks = return_masks

    # decode rle back to binary mask
    def _decode_rles(self, segmentations):
        masks = []
        for rle in segmentations:
            compressed_rle = M.frPyObjects(rle, rle.get('size')[0], rle.get('size')[1])
            mask = M.decode(compressed_rle)
            if len(mask.shape) < 3:
                mask = mask[..., None]
            mask = torch.as_tensor(mask, dtype=torch.uint8)
            mask = mask.any(dim=2)
            masks.append(mask)
        if masks:
            masks = torch.stack(masks, dim=0)
        else:
            masks = torch.zeros((0, height, width), dtype=torch.uint8)
        return masks    
    
    def _suv_to_greyPIL(self, suv_img, suv_max):
        # Assuming eval mode
        norm = plt.Normalize(vmin = 0, vmax = suv_max) # normally radiologists view images at this suv norm
        # Color map to gray images, output has 3 channels
        cmap = plt.cm.Greys
        img = cmap(norm(suv_img))[:,:,:3].copy() # drop the alpha channel that we don't need. has shape (H x W x 3C) 
        #img = torch.as_tensor(img, dtype=torch.float64) # the transforms latera will turn the numpy array to a tensor (C x H x W)
        img = Image.fromarray(np.uint8(img*255), 'RGB') # expected input by transforms
        return img
    
    def __call__(self, suv_img, target, masks, suv_max): 
        img = self._suv_to_greyPIL(suv_img, suv_max)
        #print(img.size, '####')
        
        #Basically unchanged from here on
        w, h = img.size

        image_id = target["image_id"]
        image_id = torch.tensor([image_id])

        anno = target["annotations"]

        anno = [obj for obj in anno if 'iscrowd' not in obj or obj['iscrowd'] == 0]

        boxes = [obj["bbox"] for obj in anno]
        # guard against no boxes via resizing --> code below actually turns xywh to xyxy
        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)
        boxes[:, 2:] += boxes[:, :2]
        # makes sure boxes don't go outside image
        boxes[:, 0::2].clamp_(min=0, max=w)
        boxes[:, 1::2].clamp_(min=0, max=h)
        
        classes = [obj["category_id"] for obj in anno]
        classes = torch.tensor(classes, dtype=torch.int64)

        if self.return_masks:
            segmentations = [obj["segmentation"] for obj in anno]
            masks = self._decode_rles(segmentations)

        keypoints = None
        if anno and "keypoints" in anno[0]:
            keypoints = [obj["keypoints"] for obj in anno]
            keypoints = torch.as_tensor(keypoints, dtype=torch.float32)
            num_keypoints = keypoints.shape[0]
            if num_keypoints:
                keypoints = keypoints.view(num_keypoints, -1, 3)

        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0])
        boxes = boxes[keep]
        classes = classes[keep]
        if self.return_masks:
            masks = masks[keep]
        if keypoints is not None:
            keypoints = keypoints[keep]

        target = {}
        target["boxes"] = boxes
        target["labels"] = classes
        if self.return_masks:
            target["masks"] = masks
        target["image_id"] = image_id
        if keypoints is not None:
            target["keypoints"] = keypoints

        # for conversion to coco api
        area = torch.tensor([obj["area"] for obj in anno])
        iscrowd = torch.tensor([obj["iscrowd"] if "iscrowd" in obj else 0 for obj in anno])
        target["area"] = area[keep]
        target["iscrowd"] = iscrowd[keep]

        target["orig_size"] = torch.as_tensor([int(h), int(w)])
        target["size"] = torch.as_tensor([int(h), int(w)])

        return image, target

    

def build(image_set, args):
    root = Path(args.coco_petct_path)
    assert root.exists(), f'provided COCO path {root} does not exist'
    
    mode = 'detr'
    PATHS = {
        "train": (root/ "images/train", root / "annotations" / f'{mode}_train.json'), 
        "val": (root/ "images/train", root / "annotations" / f'{mode}_val.json'), 
        "test": (root/ "images/test", root / "annotations" / f'{mode}_test.json'), # this will be set aside for final testing
    }
    img_folder, ann_file = PATHS[image_set]
    
    if image_set == 'train':
        training = True
    else:
        training = False
    
    dataset = PETCT_CocoDetection(img_folder, ann_file, transforms=make_coco_transforms(image_set)
                                 , return_masks=args.masks, training = training)
    
    return dataset    
    
    

