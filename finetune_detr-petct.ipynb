{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-confidence",
   "metadata": {},
   "source": [
    "# Prep\n",
    "\n",
    "Setting up some prior functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rational-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1+cu101 True\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-interim",
   "metadata": {},
   "source": [
    "# Load a model\n",
    "\n",
    "First we have to decide if our model should be pretrained. \n",
    "\n",
    "This greatly depends on the size of a dataset. Smaller datasets rely more on finetuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "printable-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = True\n",
    "\n",
    "if pretrained:\n",
    "    # Get pretrained weights\n",
    "    checkpoint = torch.hub.load_state_dict_from_url(\n",
    "                url='https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth',\n",
    "                map_location='cpu',\n",
    "                check_hash=True)\n",
    "\n",
    "    # Remove class weights\n",
    "    del checkpoint[\"model\"][\"class_embed.weight\"]\n",
    "    del checkpoint[\"model\"][\"class_embed.bias\"]\n",
    "\n",
    "    # SaveOGH\n",
    "    torch.save(checkpoint,\n",
    "               'detr-r50_no-class-head.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-asthma",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Our dataset should be loadable as a COCO format\n",
    "\n",
    "This allows us to use the pycocotools to load the data dict for the main python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laden-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, implement your own coco-type dataset loader in datasets and add this \"key\" to datasets/__init__.py\n",
    "dataset_file = \"coco_petct\" \n",
    "\n",
    "# should lead to a directory with a train2017 and val2017 folder as well as an annotations folder\n",
    "#dataDir='/COCO_dataset/' \n",
    "#dataDir = '/media/storage/Joy/datasets/DETR_MIP/FDG-PET-CT-Lesions/'\n",
    "dataDir = '/gpfs/fs0/data/stanford_data/petct/DETR_MIP/FDG-PET-CT-Lesions/'\n",
    "\n",
    "# this int should be the actual number of classes + 1 (for no class)\n",
    "num_classes = 1 \n",
    "\n",
    "outDir = 'outputs'\n",
    "resume = \"detr-r50_no-class-head.pth\" if pretrained else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d305a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations  images\r\n"
     ]
    }
   ],
   "source": [
    "!ls $dataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad2ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original list 1 : [{'id': 1}, {'id': 2}, {'id': 3}]\n",
      "The original list 2 : [{'id': 1}, {'id': 2}, {'id': 3}]\n",
      "List 1 after shuffle :  [{'id': 2}, {'id': 3}, {'id': 1}]\n",
      "List 2 after shuffle :  [{'id': 2}, {'id': 3}, {'id': 1}]\n"
     ]
    }
   ],
   "source": [
    "data_list = [0,1,2,3,4,5,6,7,8]\n",
    "new_list = [data_list[i:i+3] for i in range(0, len(data_list), 3)]\n",
    "new_list\n",
    "\n",
    "list(range(0,5))\n",
    "\n",
    "import random\n",
    " \n",
    "# initializing lists\n",
    "# test_list1 = [6, 4, 8, 9, 10]\n",
    "# test_list2 = [1, 2, 3, 4, 5]\n",
    "test_list1 = [{'id':1},{'id':2},{'id':3}]\n",
    "test_list2 = [{'id':1},{'id':2},{'id':3}]\n",
    " \n",
    "# printing lists\n",
    "print(f\"The original list 1 : {test_list1}\")\n",
    "print(f\"The original list 2 : {test_list2}\")\n",
    " \n",
    "# Shuffle two lists with same order\n",
    "# Using zip() + * operator + shuffle()\n",
    "temp = list(zip(test_list1, test_list2))\n",
    "random.shuffle(temp)\n",
    "res1, res2 = zip(*temp)\n",
    "# res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "res1, res2 = list(res1), list(res2)\n",
    " \n",
    "# Printing result\n",
    "print(f\"List 1 after shuffle :  {res1}\")\n",
    "print(f\"List 2 after shuffle :  {res2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-version",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "We use the main.py script to run our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py \\\n",
    "  --dataset_file $dataset_file \\\n",
    "  --coco_path $dataDir \\\n",
    "  --output_dir $outDir \\\n",
    "  --resume $resume \\\n",
    "  --num_classes $num_classes \\\n",
    "  --lr 1e-5 \\\n",
    "  --lr_backbone 1e-6 \\\n",
    "  --epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-sister",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "Quick and easy overview of the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plot_utils import plot_logs\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "log_directory = [Path(outDir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss',\n",
    "    'mAP',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'loss_ce',\n",
    "    'loss_bbox',\n",
    "    'loss_giou',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = (\n",
    "    'class_error',\n",
    "    'cardinality_error_unscaled',\n",
    "    )\n",
    "\n",
    "plot_logs(log_directory,\n",
    "          fields_of_interest)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detr_py38",
   "language": "python",
   "name": "detr_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
